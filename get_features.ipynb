{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import ast\n",
    "import rioxarray as rxr\n",
    "from pyproj import Proj, Transformer, CRS\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_building_footprint_area_data(ground_df):\n",
    "    buildings_df = pd.read_csv('Processed_Building_Footprints.csv')\n",
    "    buildings_df = buildings_df.drop(columns = ['path', 'id', 'tessellate', 'extrude', 'visibility'])\n",
    "\n",
    "    buildings_df['coordinates'] = buildings_df['coordinates'].apply(ast.literal_eval)\n",
    "    buildings_df['geometry'] = buildings_df['coordinates'].apply(Polygon)\n",
    "\n",
    "    gdf_buildings = gpd.GeoDataFrame(buildings_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "    gdf_ground = gpd.GeoDataFrame(\n",
    "        ground_df,\n",
    "        geometry=gpd.points_from_xy(ground_df['Longitude'], ground_df['Latitude']),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "\n",
    "    gdf_buildings = gdf_buildings.to_crs(\"EPSG:32618\")\n",
    "    gdf_ground = gdf_ground.to_crs(\"EPSG:32618\")\n",
    "\n",
    "    def calculate_building_area(point, buildings, buffer_size):\n",
    "        buffer = point.buffer(buffer_size)\n",
    "        intersecting_buildings = buildings[buildings.intersects(buffer)]\n",
    "        total_area = intersecting_buildings.geometry.intersection(buffer).area.sum()\n",
    "        return total_area\n",
    "\n",
    "    gdf_ground['building_area_25']  = gdf_ground.geometry.apply(lambda pt: calculate_building_area(pt, gdf_buildings, 25))\n",
    "    gdf_ground['building_area_50']  = gdf_ground.geometry.apply(lambda pt: calculate_building_area(pt, gdf_buildings, 50))\n",
    "    gdf_ground['building_area_100'] = gdf_ground.geometry.apply(lambda pt: calculate_building_area(pt, gdf_buildings, 100))\n",
    "\n",
    "    # Optionally, convert back to a pandas DataFrame if you don't need the geometry column:\n",
    "    result_df = pd.DataFrame(gdf_ground.drop(columns='geometry'))\n",
    "\n",
    "    return(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands(df):\n",
    "    \n",
    "    # Load the GeoTIFF data\n",
    "    data = rxr.open_rasterio(\"S2_sample.tiff\")\n",
    "    tiff_crs = data.rio.crs\n",
    "\n",
    "    # Read the Excel file using pandas\n",
    "    latitudes = df['Latitude'].values\n",
    "    longitudes = df['Longitude'].values\n",
    "\n",
    "    # 3. Convert lat/long to the GeoTIFF's CRS\n",
    "    # Create a Proj object for EPSG:4326 (WGS84 - lat/long) and the GeoTIFF's CRS\n",
    "    proj_wgs84 = Proj(init='epsg:4326')  # EPSG:4326 is the common lat/long CRS\n",
    "    proj_tiff = Proj(tiff_crs)\n",
    "    \n",
    "    # Create a transformer object\n",
    "    transformer = Transformer.from_proj(proj_wgs84, proj_tiff)\n",
    "\n",
    "    B01_values = []\n",
    "    B02_values = []\n",
    "    B03_values = []\n",
    "    B04_values = []\n",
    "    B05_values = []\n",
    "    B06_values = []\n",
    "    B07_values = []\n",
    "    B08_values = []\n",
    "    B8A_values = []\n",
    "    B11_values = []\n",
    "    B12_values = []\n",
    "\n",
    "# Iterate over the latitudes and longitudes, and extract the corresponding band values\n",
    "    for lat, lon in tqdm(zip(latitudes, longitudes), total=len(latitudes), desc=\"Mapping values\"):\n",
    "    # Assuming the correct dimensions are 'y' and 'x' (replace these with actual names from data.coords)\n",
    "    \n",
    "        B01_value = data.sel(x=lon, y=lat,  band=1, method=\"nearest\").values\n",
    "        B01_values.append(B01_value)\n",
    "    \n",
    "        B02_value = data.sel(x=lon, y=lat, band=2, method=\"nearest\").values\n",
    "        B02_values.append(B02_value)\n",
    "        \n",
    "        B03_value = data.sel(x=lon, y=lat, band=3, method=\"nearest\").values\n",
    "        B03_values.append(B03_value)\n",
    "    \n",
    "        B04_value = data.sel(x=lon, y=lat, band=4, method=\"nearest\").values\n",
    "        B04_values.append(B04_value)\n",
    "                \n",
    "        B05_value = data.sel(x=lon, y=lat,  band=5, method=\"nearest\").values\n",
    "        B05_values.append(B05_value)\n",
    "    \n",
    "        B06_value = data.sel(x=lon, y=lat, band=6, method=\"nearest\").values\n",
    "        B06_values.append(B06_value)\n",
    "        \n",
    "        B07_value = data.sel(x=lon, y=lat, band=7, method=\"nearest\").values\n",
    "        B07_values.append(B07_value)\n",
    "    \n",
    "        B08_value = data.sel(x=lon, y=lat, band=8, method=\"nearest\").values\n",
    "        B08_values.append(B08_value)\n",
    "        \n",
    "        B8A_value = data.sel(x=lon, y=lat,  band=9, method=\"nearest\").values\n",
    "        B8A_values.append(B8A_value)\n",
    "    \n",
    "        B11_value = data.sel(x=lon, y=lat, band=10, method=\"nearest\").values\n",
    "        B11_values.append(B11_value)\n",
    "        \n",
    "        B12_value = data.sel(x=lon, y=lat, band=11, method=\"nearest\").values\n",
    "        B12_values.append(B12_value)\n",
    "    \n",
    "    # Create a DataFrame with the band values\n",
    "    # Create a DataFrame to store the band values\n",
    "    df['B01'] = B01_values\n",
    "    df['B02'] = B02_values\n",
    "    df['B03'] = B03_values\n",
    "    df['B04'] = B04_values\n",
    "    df['B05'] = B05_values\n",
    "    df['B06'] = B06_values\n",
    "    df['B07'] = B07_values\n",
    "    df['B08'] = B08_values\n",
    "    df['B8A'] = B8A_values\n",
    "    df['B11'] = B11_values\n",
    "    df['B12'] = B12_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    bfa = get_building_footprint_area_data(df)\n",
    "    bands = get_bands(df)\n",
    "\n",
    "    merged_df = pd.merge(bfa, \n",
    "                         bands,\n",
    "                         on=['Longitude', 'Latitude', 'UHI Index'])\n",
    "    \n",
    "    return(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexyi/Desktop/school/vs_code/dat_eng_200/EY-Data-Chal/.venv/lib/python3.13/site-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "Mapping values: 100%|██████████| 1040/1040 [00:03<00:00, 276.85it/s]\n"
     ]
    }
   ],
   "source": [
    "validation1 = get_data(pd.read_csv('Submission_template_UHI2025-v2.csv'))\n",
    "validation = pd.merge(validation1,\n",
    "                      pd.read_csv('validation_weather.csv'),\n",
    "                      on=['Longitude', 'Latitude', 'UHI Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('light_building_weather_data.csv')\n",
    "train_data = train_data.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "X = train_data.drop(columns=['Longitude', \n",
    "                            'Latitude', \n",
    "                            'datetime', \n",
    "                            'UHI Index',\n",
    "                            'Area'])\n",
    "y = train_data['UHI Index']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [500,600,800],\n",
    "    'max_depth': [None, 50,75,100],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Fit to training data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_test = validation.drop(columns=['Longitude', 'Latitude', 'UHI Index','datetime', 'Unnamed: 0'])\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = best_rf.predict(validation_test)\n",
    "final_predictions_series = pd.Series(final_predictions)\n",
    "\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({'Longitude':validation['Longitude'].values, \\\n",
    "                               'Latitude':validation['Latitude'].values, \\\n",
    "                                'UHI Index':final_predictions_series.values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('Submission_template_UHI2025-v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(validation_df['Latitude'] == submission_df['Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-73.971665)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['Longitude'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-73.971665)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df['Longitude'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('67053f23bf0662f09fed2f3a-679bc36eb6a3410a9ebc6888-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sub1['Longitude'] == submission_df['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
