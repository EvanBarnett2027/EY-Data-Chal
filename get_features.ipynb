{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, Point\n",
    "import ast\n",
    "import rioxarray as rxr\n",
    "from pyproj import Proj, Transformer, CRS\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_building_footprint_area_data(ground_df):\n",
    "    buildings_df = pd.read_csv('Processed_Building_Footprints.csv')\n",
    "    buildings_df = buildings_df.drop(columns = ['path', 'id', 'tessellate', 'extrude', 'visibility'])\n",
    "\n",
    "    buildings_df['coordinates'] = buildings_df['coordinates'].apply(ast.literal_eval)\n",
    "    buildings_df['geometry'] = buildings_df['coordinates'].apply(Polygon)\n",
    "\n",
    "    gdf_buildings = gpd.GeoDataFrame(buildings_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "    gdf_ground = gpd.GeoDataFrame(\n",
    "        ground_df,\n",
    "        geometry=gpd.points_from_xy(ground_df['Longitude'], ground_df['Latitude']),\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "\n",
    "    gdf_buildings = gdf_buildings.to_crs(\"EPSG:32618\")\n",
    "    gdf_ground = gdf_ground.to_crs(\"EPSG:32618\")\n",
    "\n",
    "    def calculate_building_area(point, buildings, buffer_size):\n",
    "        buffer = point.buffer(buffer_size)\n",
    "        intersecting_buildings = buildings[buildings.intersects(buffer)]\n",
    "        total_area = intersecting_buildings.geometry.intersection(buffer).area.sum()\n",
    "        return total_area\n",
    "\n",
    "    gdf_ground['building_area_25']  = gdf_ground.geometry.apply(lambda pt: calculate_building_area(pt, gdf_buildings, 25))\n",
    "    gdf_ground['building_area_50']  = gdf_ground.geometry.apply(lambda pt: calculate_building_area(pt, gdf_buildings, 50))\n",
    "    gdf_ground['building_area_100'] = gdf_ground.geometry.apply(lambda pt: calculate_building_area(pt, gdf_buildings, 100))\n",
    "\n",
    "    # Optionally, convert back to a pandas DataFrame if you don't need the geometry column:\n",
    "    result_df = pd.DataFrame(gdf_ground.drop(columns='geometry'))\n",
    "\n",
    "    return(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bands(df):\n",
    "    \n",
    "    # Load the GeoTIFF data\n",
    "    data = rxr.open_rasterio(\"S2_sample.tiff\")\n",
    "    tiff_crs = data.rio.crs\n",
    "\n",
    "    # Read the Excel file using pandas\n",
    "    latitudes = df['Latitude'].values\n",
    "    longitudes = df['Longitude'].values\n",
    "\n",
    "    # 3. Convert lat/long to the GeoTIFF's CRS\n",
    "    # Create a Proj object for EPSG:4326 (WGS84 - lat/long) and the GeoTIFF's CRS\n",
    "    proj_wgs84 = Proj(init='epsg:4326')  # EPSG:4326 is the common lat/long CRS\n",
    "    proj_tiff = Proj(tiff_crs)\n",
    "    \n",
    "    # Create a transformer object\n",
    "    transformer = Transformer.from_proj(proj_wgs84, proj_tiff)\n",
    "\n",
    "    B01_values = []\n",
    "    B02_values = []\n",
    "    B03_values = []\n",
    "    B04_values = []\n",
    "    B05_values = []\n",
    "    B06_values = []\n",
    "    B07_values = []\n",
    "    B08_values = []\n",
    "    B8A_values = []\n",
    "    B11_values = []\n",
    "    B12_values = []\n",
    "\n",
    "# Iterate over the latitudes and longitudes, and extract the corresponding band values\n",
    "    for lat, lon in tqdm(zip(latitudes, longitudes), total=len(latitudes), desc=\"Mapping values\"):\n",
    "    # Assuming the correct dimensions are 'y' and 'x' (replace these with actual names from data.coords)\n",
    "    \n",
    "        B01_value = data.sel(x=lon, y=lat,  band=1, method=\"nearest\").values\n",
    "        B01_values.append(B01_value)\n",
    "    \n",
    "        B02_value = data.sel(x=lon, y=lat, band=2, method=\"nearest\").values\n",
    "        B02_values.append(B02_value)\n",
    "        \n",
    "        B03_value = data.sel(x=lon, y=lat, band=3, method=\"nearest\").values\n",
    "        B03_values.append(B03_value)\n",
    "    \n",
    "        B04_value = data.sel(x=lon, y=lat, band=4, method=\"nearest\").values\n",
    "        B04_values.append(B04_value)\n",
    "                \n",
    "        B05_value = data.sel(x=lon, y=lat,  band=5, method=\"nearest\").values\n",
    "        B05_values.append(B05_value)\n",
    "    \n",
    "        B06_value = data.sel(x=lon, y=lat, band=6, method=\"nearest\").values\n",
    "        B06_values.append(B06_value)\n",
    "        \n",
    "        B07_value = data.sel(x=lon, y=lat, band=7, method=\"nearest\").values\n",
    "        B07_values.append(B07_value)\n",
    "    \n",
    "        B08_value = data.sel(x=lon, y=lat, band=8, method=\"nearest\").values\n",
    "        B08_values.append(B08_value)\n",
    "        \n",
    "        B8A_value = data.sel(x=lon, y=lat,  band=9, method=\"nearest\").values\n",
    "        B8A_values.append(B8A_value)\n",
    "    \n",
    "        B11_value = data.sel(x=lon, y=lat, band=10, method=\"nearest\").values\n",
    "        B11_values.append(B11_value)\n",
    "        \n",
    "        B12_value = data.sel(x=lon, y=lat, band=11, method=\"nearest\").values\n",
    "        B12_values.append(B12_value)\n",
    "    \n",
    "    # Create a DataFrame with the band values\n",
    "    # Create a DataFrame to store the band values\n",
    "    df['B01'] = B01_values\n",
    "    df['B02'] = B02_values\n",
    "    df['B03'] = B03_values\n",
    "    df['B04'] = B04_values\n",
    "    df['B05'] = B05_values\n",
    "    df['B06'] = B06_values\n",
    "    df['B07'] = B07_values\n",
    "    df['B08'] = B08_values\n",
    "    df['B8A'] = B8A_values\n",
    "    df['B11'] = B11_values\n",
    "    df['B12'] = B12_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    bfa = get_building_footprint_area_data(df)\n",
    "    bands = get_bands(df)\n",
    "\n",
    "    merged_df = pd.merge(bfa, \n",
    "                         bands,\n",
    "                         on=['Longitude', 'Latitude', 'UHI Index'])\n",
    "    \n",
    "    return(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexyi/Desktop/school/vs_code/dat_eng_200/EY-Data-Chal/.venv/lib/python3.13/site-packages/pyproj/crs/crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "Mapping values: 100%|██████████| 1040/1040 [00:04<00:00, 252.70it/s]\n"
     ]
    }
   ],
   "source": [
    "mixed_data = get_data(pd.read_csv('Submission_template_UHI2025-v2.csv'))\n",
    "building_and_light = pd.read_csv('building_and_light_data.csv')\n",
    "building_and_light = building_and_light.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "X = building_and_light.drop(columns=['Longitude', \n",
    "                            'Latitude', \n",
    "                            'datetime', \n",
    "                            'UHI Index'])\n",
    "y = building_and_light['UHI Index']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [300,400,500],\n",
    "    'max_depth': [None, 30, 40, 50],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2246, 1040]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m outsample_predictions \u001b[38;5;241m=\u001b[39m best_rf\u001b[38;5;241m.\u001b[39mpredict(validation_test)\n\u001b[1;32m      5\u001b[0m Y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest R^2 Scored: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutsample_predictions\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/school/vs_code/dat_eng_200/EY-Data-Chal/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/school/vs_code/dat_eng_200/EY-Data-Chal/.venv/lib/python3.13/site-packages/sklearn/metrics/_regression.py:1257\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03mBest possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;124;03m-inf\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m xp, _, device_ \u001b[38;5;241m=\u001b[39m get_namespace_and_device(\n\u001b[1;32m   1253\u001b[0m     y_true, y_pred, sample_weight, multioutput\n\u001b[1;32m   1254\u001b[0m )\n\u001b[1;32m   1256\u001b[0m _, y_true, y_pred, sample_weight, multioutput \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1257\u001b[0m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m )\n\u001b[1;32m   1262\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/school/vs_code/dat_eng_200/EY-Data-Chal/.venv/lib/python3.13/site-packages/sklearn/metrics/_regression.py:198\u001b[0m, in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mregression task.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dtype_name \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m--> 198\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/school/vs_code/dat_eng_200/EY-Data-Chal/.venv/lib/python3.13/site-packages/sklearn/metrics/_regression.py:104\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mTo reduce redundancy when calling `_find_matching_floating_dtype`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m--> 104\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    106\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Desktop/school/vs_code/dat_eng_200/EY-Data-Chal/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2246, 1040]"
     ]
    }
   ],
   "source": [
    "validation_test = mixed_data.drop(columns=['Longitude', 'Latitude', 'UHI Index'])\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "Y_test = y_test.tolist()\n",
    "print(\"Test R^2 Scored: \",r2_score(Y_test, outsample_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = best_rf.predict(validation_test)\n",
    "final_predictions_series = pd.Series(final_predictions)\n",
    "\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({'Longitude':mixed_data['Longitude'].values, \\\n",
    "                               'Latitude':mixed_data['Latitude'].values, \\\n",
    "                                'UHI Index':final_predictions_series.values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
